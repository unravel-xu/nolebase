# 用中学数学从零开始理解大型语言模型

原文链接：[Understanding LLMs from Scratch Using Middle School Math](https://towardsdatascience.com/understanding-llms-from-scratch-using-middle-school-math-e602d27ec876/)

参考译文：[中学生就能看懂：从零开始理解LLM内部原理](https://mp.weixin.qq.com/s?__biz=Mzk1NzQ1ODk5NQ==&mid=2247522402&idx=1&sn=9aab727e53e1f63cff791f6e745c057c&scene=21#wechat_redirect)

本文中将从头开始讲解大语言模型（LLM）的工作原理——假设你只会加法和乘法，也不会引用其他知识来源。我们从用纸和笔构建一个简单的神经网络模型开始，然后逐步深入，带你全面理解现代 LLM 和 Transformer 架构的所有细节。文章会尽量剥离掉机器学习中的复杂术语和行话，把所有内容还原为最简单的形式：数字。但必要时我们会解释相关术语，以便你在阅读带有术语的内容时能有所参照。

理论上，一个有决心的人可以基于这里的所有信息重现一个现代的 LLM，因此文章覆盖的内容非常多，也不适合“随便看看”。我们会讲解如下内容：

[toc]

你可以把神经网络模型看作一个魔法“盒子”，放进去一些信息，会“吐出“你期望的信息。比如，放进去一张图片，输出图片的类别；放进去一段文字，输出文字的情感类别。但要注意的是，**神经网络只能接受数字作为输入，也只能输出数字——没有例外**。所以，设计的核心就在于如何将输入转化为数字，将输出数字解释为对目标的实现，最终构建能够处理你提供的输入信息，并生成所需输出信息的神经网络

## 一个简单的神经网络

现在来看如何用加法与乘法构建一个能够对物体进行分类的简单神经网络。在这个模型中：