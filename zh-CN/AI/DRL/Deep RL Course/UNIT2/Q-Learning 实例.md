# Q-Learning 实例

为了更好的理解 Q-learning 算法，我们举一个简单的例子：

![[pic-20250315182457831.png]]

- 假设有一只处在迷宫中的小老鼠，并总是从相同的起点开始出发
- 目标是吃掉右下角的大奶酪且不能吃到毒药
- 每轮探索，如果吃到毒药、吃掉大块奶酪或行动超过 5 步，探索结束
- learning rate = 0.1    discount rate(gamma) = 0.99

奖励函数如下：

- +0：去一个没有奶酪的状态
- +1：去一个有小奶酪的状态
- +10：去一个有一大堆奶酪的状态
- -10：去一个有毒药的状态且会死亡
- +0：如果我们执行超过五步

如下使用 Q-Learning 算法训练智能体，使其能够学会最优策略（依次执行向右、向右、向下）

## 第一步：初始化 Q-table

![[pic-20250315220528183.png]]

初始时，Q-table 没什么用，需用使用 Q-Learning 算法训练 Q-function

我们进行 2 个训练时间步骤：

训练时间步骤 1：

## 第二步：使用 Epsilon Greedy 策略选择动作

初始 epsilon = 1，所以会采取随机动作，假设随机选择了向右的动作

![[pic-20250315221715732.png]]

## 第三步：执行动作 $A_{t}$，得到 $R_{t+1}$ 和 $S_{t+1}$

向右走得到一小块奶酪，所以 $R_{t+1}=1$，并进入新的状态

![[pic-20250315223024751.png]]

## 第四步：更新 $Q\left(S_{t},A_{t}\right)$

根据公式更新 $Q\left(S_{t},A_{t}\right)$：

![[pic-20250315223222539.png]]

