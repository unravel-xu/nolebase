# 介绍

在上一单元，我们学习了第一个强化学习算法：Q-Learning

我们通过简单的算法就取得了极佳的结果，但是 FrozenLake-v1 ☃️ 和 Taxi-v3 🚕 的状态空间很小且是离散的（FrozenLake-v1 ☃️ 有 16 种不同状态，Taxi-v3 🚕 有 500 种）相比之下，游戏雅达利（Atari）的状态空间包含 $10^9\sim10^{11}$ 种状态

我们将看到，当环境的状态空间很大时，生成和更新 Q-table 可能会失效

在本单元中，我们会学习第一个深度强化学习算法：Deep Q-Learning。Deep Q-Leaning 用神经网络代替了 Q-Learning 中的 Q-table，该神经网络接收一个状态输入，并输出该状态下每个动作的近似 Q-value

然后我们将使用 [RL-Zoo](https://github.com/DLR-RM/rl-baselines3-zoo)（一个使用 Stable-Baselines 提供训练脚本，评估智能体，微调超参数，绘制结果和记录视频的强化学习训练框架）训练智能体玩太空侵略者（Space Invaders）和其他雅达利游戏（Atari）

![[atari-envs.gif]]
