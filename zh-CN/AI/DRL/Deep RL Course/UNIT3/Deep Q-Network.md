# Deep Q-Network(DQN)

如下是 Deep Q-Learning 网络的结构：

![[pic-20250317204149456.png]]

我们将 4 帧图像堆叠起来作为一个状态输入，传递给神经网络，神经网络会输出该状态下每个可能动作的 Q-value 向量。然后和 Q-Learning 一样，使用 epsilon-greedy policy 选取动作

当神经网络初始化时，Q 值的估计是非常不准确的。但是随着训练进行，DQN（Deep Q-Network）智能体会将当前状态与合适的动作关联起来，并学会如何玩好游戏

## 预处理输入和时序限制

我们需要预处理输入，通过减少状态的复杂度从而减少训练的计算时间