# Huggy 介绍

Huggy 是由 Hugging Face 制作的深度强化学习环境，基于 Unity MLAgents 团队的项目 Puppo the Corgi。此环境通过 Unity 游戏引擎和 MLAgents 创建。ML-Agents 是 Unity 游戏引擎的工具包，允许用户利用 Unity 创建环境或使用预制环境来训练智能体

![[pic-20250312230042040.png]]

在这个环境下，我们的目标是训练 Huggy 捡起扔的木棍，这要求 Huggy 能正确地朝着棍子移动

## Huggy 感知的状态空间

Huggy 无法“看到”它所处的环境，只能由我们向它提供有关环境的信息：
- 目标（木棍）位置
- Huggy 和目标之间的相对位置
- Huggy 腿的朝向

通过提供的信息，Huggy 可以根据 policy 决定下一步采取的 action

## Huggy 执行的动作空间

![[pic-20250312233139798.png]]

Huggy 的腿由关节电机驱动，如图所示，Huggy 需要学会正确地旋转每条腿的关节马达，才能移动

## 奖励函数

设计奖励函数是为了让 Huggy 能捡起木棍

我们既要让 Huggy 朝着木棍走去，又要求它不要拐太多弯。因此，奖励函数必须转化为这个目标（由奖励假设可知，我们可以完成这种转化）

奖励函数包含：
- 方向奖励：当 Huggy 接近目标时，给予它奖励
- 时间惩罚：在每个动作中给予的固定时间惩罚，迫使 Huggy 尽快到达木棍
- 旋转惩罚：如果Huggy旋转太多并且转弯太快，我们会对Huggy进行惩罚
- 到达目标奖励：当 Huggy 到达目标，给予它奖励

## 训练 Huggy

训练循环如下：

![[pic-20250313085837615.png]]

训练环境中会随机生成木棍，当 Huggy 到达木棍时，木棍会重新生成在其他地点。我们为训练构建了环境的多个副本，从而通过多样化的经验来加快训练

我们将直接使用 [MLAgents](https://github.com/Unity-Technologies/ml-agents) 提供的实现，后续课程会深入了解 MLAgents 的运行原理